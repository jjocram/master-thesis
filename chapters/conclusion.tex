\documentclass[../thesis.tex]{subfiles}
\begin{document}
\chapter{Conclusion}\label{cap:conclusion}
% HRI 
Through the work done in this thesis, a novel framework to simplify human robot interaction has been proposed, implemented with Python, tested in a Gazebo simulation, and documented to enable other people to use and improve it. The idea behind the framework is to use the hand to control a robot. This was successfully achieved by exploiting MediaPipe to track hands in real-time and two deep neural networks to classify which hand gesture the users are doing by exploiting the coordinates of the hand's conjunctions obtained from MediaPipe. Moreover, the framework handles the communication with the robot through the \gls{ROS} framework. In this way, the developed framework can communicate with any kind of robot, as long as it is compatible with \gls{ROS}.\\

% How to recognize hand gestures
Thanks to the combination of MediaPipe and light deep neural networks (less than ten layers) a set of dynamic and static hand gestures can be recognized in real-time and the training process is really fast. Moreover, the addition of a new gesture is really easy and can be done in a couple of minutes. This is achievable because to recognize hand gestures, the framework uses only the coordinates of twenty-one landmarks representing the junctions of the hand and a sequence of them in the case of dynamic hand gestures.\\

The possibility to add new gestures ``to the need'' opens the framework to several scenarios. To handle all the possible input sequences and related actions for the robot to perform, the framework asks the users to declare a finite state automaton through a configuration file whose structure was made as simple as possible. In this way, anyone can relate a sequence of gestures to actions performed by a robot.\\

% Integration with ROS
The integration with \gls{ROS} is just at the beginning. At the moment, users can only set a navigation goal and publish a message on a topic. Nevertheless, as a proof-of-concept of what is possible to achieve with this framework, it has been tested in a warehouse environment. The \gls{ASL} has been used as static hand gestures to recognize and six gestures taken from the literature have been used as dynamic hand gestures to recognize. Thanks to the framework's integration with Nav2 as the navigation system and \gls{ROS}' topics, a finite state automaton has been described to achieve several tasks, for example, going to a position, picking up a parcel, and dropping off the parcel. The simulation has been done with Gazebo and the AWS small warehouse as ``Gazebo world''.\\

% Macros
In addition, a way to describe macros has been implemented. In this way, users can pre-record a sequence of gestures and run it at another moment or edit it with any text editor. The correctness of the sequence is enforced by the same automaton that enforces the correctness of the users input in the real-time scenario.\\

% Why experiments have been carried on
Furthermore, several tests have been performed to evaluate the quality of the implementation. Those concerning system resource utilization, in particular, are encouraging in terms of a possible deployment on real hardware such as an NVIDIA Jetson Nano or a Raspberry-Pi, two boards widely used in the robot and automation ecosystem.\\

% TODO: limitations and challenges => future works
The solution proposed is not without limitations and challenges to overcome. In particular, the integration with \gls{ROS} is just at the beginning. For example, the framework can work only with Nav2 as theÂ navigation system and can only send messages through topics. In future development, the framework should be able to use different navigation systems and exploit all the capabilities provided by \gls{ROS} to exchange messages. Moreover, the \gls{ROS} community is active and there are a lot of developers who are creating new \gls{ROS}' packages; the framework should be able to integrate with them as it does with Nav2. This would make it really easy for the community around the development of robotic applications to exploit the capability of the framework when the simplification of the \gls{HRI} is taken into consideration.

\end{document}
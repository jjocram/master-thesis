\documentclass[../thesis.tex]{subfiles}
\begin{document}
\chapter{Background}\label{cap:background}

\section{Human-Robot Interaction}

\section{Hand gesture recognition}
The hand gesture recognition task is a well-studied task. In the literature is possible to find the idea to use the hand gesture as a way to interact with a machine since 1987~\cite{article:hand_gesture_interface_device}. At that time the idea was to use a glove to recognize the position and the orientation of the user's hand. They were thought to be used for different tasks like gesture recognition, an interface to a visual programming language, virtual object manipulation, and many others. Nowadays, even if a third-party device to recognize what the hands are doing is highly accurate and precise, for some tasks it is possible to reach a good level of accuracy with only a webcam. Especially, thanks to the increase of computing power, also in small devices and the improved quality of video acquisition devices, the study of computer vision and machine learning techniques to recognize hand gestures is becoming very interesting.

\subsection{Machine learning}
Recognizing a hand gesture given an image or a frame of a video is not something easily algorithmizable. For this, the idea of using a neural network to fulfill the task is a good one.

\subsubsection{Dataset}
When \acrshort{ML} is involved, the challenge is the need for big datasets on which the network can train. When image recognition is the task to fulfill, the datasets are composed of a lot of images and each one must be labeled to know what it is representing and where, inside the image, the position of the object to detect is. This kind of training is known as supervised learning which is different from the unsupervised in which the dataset has no labels and usually the task is to categorize the elements into macro-categories.

\subsubsection{Evaluation}
To evaluate an \acrshort{ML} model is necessary to collect some data during the training process. The metrics to keep track of are:
\begin{itemize}
    \item \textbf{loss function}: what the network aims to minimize. Generally, it represents the prediction error with respect to the ground truth.
    \item \textbf{accuracy}: is the ratio between the number of correct predictions, and the total number of predictions made.
        \begin{equation}
                Accuracy = \frac{Number\, of\, right\, predictions}{Number\, of\, predictions}
        \end{equation}
    \item \textbf{time}: the time spent on training the network. It depends on the dataset size and the complexity of the network. Specifically, a bigger dataset will require more time but will give better results as well as a more complex network.
\end{itemize}
The best neural network is the one that guarantees the best trade-off between these metrics.

\subsubsection{State of the art}
At present, there are several ways to achieve good results in the hand gesture recognition task with the help of neural networks. The results presented in~\citeauthor{article:survey_on_vision_based_hand_gesture_recognition}~\cite{article:survey_on_vision_based_hand_gesture_recognition} shows that with a \acrfull{CNN} is possible to achieve accuracy higher than the $90\%$. \acrshortpl{CNN} are classifier-based systems that can process input images as structured arrays of data and identify patterns between them. To date, there are two main types of object detection algorithms in the field of deep learning:
\begin{itemize}
    \item \textbf{Classification-based algorithms}: firstly, they select a group of \acrfullpl{ROI} in the images where the chances that an object is present are high; secondly, they apply \acrshort{CNN} techniques to these selected regions to detect the presence of an object. A problem associated with these types of algorithms is that they need to execute a detector in each \acrshort{ROI}, and this makes the process of object detection very slow and highly expensive in terms of computation.
    \item \textbf{Regression-based algorithms}: these types of algorithms are faster than the above algorithms, in that there is no selection of the \acrshort{ROI} so that the bounding boxes and the labels are predicted for the whole image at once; they can identify and classify objects within the image at once. Beyond the higher speed, a key point is that the predictions are informed by the global context in the image, thus they generally lead to higher accuracies.
\end{itemize}
One of the most famous regression-based algorithms is \glsfirst{YOLO}, but it is not the only possible solution to perform this kind of task. Another technique, that gives promising results is the combination of the MediaPipe hand tracker, which~\ref{sec:mediapipe} describes, and a feed-forward neural network to recognize the gesture.\\
All thess kind of solutions suit well in the case of static hand gestures. As \citeauthor{site:hand_gesture_base_repo} shows in his repository\cite{site:hand_gesture_base_repo}, working with a history of landmarks is possible. For this kind of task, a \glsfirst{LSTM} neural network is a good starting point. This kind of network tries to add the knowledge of past events to the computation, to do so there are loops inside them allowing information to persist~\cite{site:understanding_lstm_networks}.

\end{document}
